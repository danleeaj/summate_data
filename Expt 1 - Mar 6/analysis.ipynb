{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "Each of the files within `data/` should contain the following:\n",
    "* A JSON formatted string that have the keys 'score' and 'explanation', which describe the score given to the student response by the autograder, and the explanation behind it.\n",
    "* A PredictionStats object formatted into a string, which contain information on the token count, time taken, etc. This is important in the future for calculating computing power consumption.\n",
    "However, this is not the case in every file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'explanation': 'The student has partially met all criteria: The dataset is resampled with replacement multiple times (1 point), but it\\'s not specified if this is done n times where n is the size of the dataset, so 1/2 point for the first criterion. The new resampled datasets are used to obtain coefficients such as residuals and gradient of the line of best fit, which is then plotted together in a histogram and summary statistics are obtained (4 points).',\n",
      "  'score': 5\n",
      "}\n",
      "LlmPredictionStats.from_dict({\n",
      "  \"numGpuLayers\": -1.0,\n",
      "  \"predictedTokensCount\": 109,\n",
      "  \"promptTokensCount\": 233,\n",
      "  \"stopReason\": \"eosFound\",\n",
      "  \"timeToFirstTokenSec\": 0.039,\n",
      "  \"tokensPerSecond\": 26.32290085129227,\n",
      "  \"totalTokensCount\": 342\n",
      "})"
     ]
    }
   ],
   "source": [
    "with open('data/expt_temp_0_resp_10_run_4.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the JSON object, there is also a short output from the LLM. One method to address this would be to use a structured output, however, preliminary studies done using structured output resulted in simple, one-line explanations that do not address the rubric. Standardizing the output will be something we investigate further down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "The most important thing for us to extract from this data is the score, specifically, the `int` following the score. Since all scores seem to be following the format of `'score': [some int]`, we will use regular expressions to extract the score from every file. Along with the score, we will also collect diagnostic information from the `LlmPredictionStats` object. The regex should be able to detect the following patterns:\n",
    "* `'score': 6`\n",
    "* `\"score\": 6`\n",
    "* `'score' : 6`\n",
    "\n",
    "At the same time, we'll extract information about the student response ID, the temperature, as well as the repeat number for each of the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6', '6', '6', '6']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"'score': 6\", \"\\\"score\\\": 6\", \"'score' : 6\", \"'score':6\"]\n",
    "\n",
    "pattern = r\"[\\'\\\"]\\s*score\\s*[\\'\\\"]\\s*:\\s*(\\d+)\"\n",
    "scores = []\n",
    "\n",
    "for snippet in test:\n",
    "    match = re.search(pattern, snippet)\n",
    "    if match:\n",
    "        match = match.group(1)\n",
    "    else:\n",
    "        match = None\n",
    "    scores.append(match)\n",
    "\n",
    "scores\n",
    "\n",
    "# Regex works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[\\'\\\"]\\s*score\\s*[\\'\\\"]\\s*:\\s*(\\d+)\"\n",
    "data = []\n",
    "\n",
    "for file in os.listdir('data'):\n",
    "    file = 'data/'+file\n",
    "\n",
    "    # print(f\"Analyzing file: {file}\")\n",
    "\n",
    "    # We open the file and search for the regex pattern\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # print(f\"Analyzing line: {line}\", end=\"\")\n",
    "            match = re.search(pattern, line)\n",
    "            # If we find a match, then we store it in match, and we break out of the loop\n",
    "            if match:\n",
    "                match = int(match.group(1))\n",
    "                # print(f\"Score found: {match}\")\n",
    "                break\n",
    "        # Since the inference metadata is always the last 9 lines, we extract the last 9 lines for processing later\n",
    "        inference_metadata = lines[-9:]\n",
    "\n",
    "    # If, after it loops through the entire file, a match cannot be found, it is set to None\n",
    "    if not match:\n",
    "        match = None\n",
    "\n",
    "    # Then we use regex to extract information about the run itself\n",
    "    run_metadata = re.search(r\"temp_(0|0\\.2|0\\.4|0\\.6|0\\.8|1)_resp_(\\d*)_run_(\\d*)\", file)\n",
    "    temperature, response, repeat = float(run_metadata.group(1)), int(run_metadata.group(2)), int(run_metadata.group(3))\n",
    "\n",
    "    # Although this should not yield an error, just in case, we will wrap it inside a try/except block.\n",
    "    try:\n",
    "        # We then extract the inference metadata. Because this was directly generated by LMStudio, there should not be any formatting issues. So we'll just use split.\n",
    "        inference_metadata = ''.join(inference_metadata)\n",
    "        # Remove the brackets, and turn it into a JSON formatted string\n",
    "        inference_metadata = inference_metadata.replace('LlmPredictionStats.from_dict(', '').rstrip(')')\n",
    "        # Then use\n",
    "        inference_metadata = json.loads(inference_metadata)\n",
    "    # This way if any error happens, the code does not just crash, it just stores it as none\n",
    "    except Exception as e:\n",
    "        inference_metadata = None\n",
    "\n",
    "    # Now that all data is prepared, we can store it into a dictionary to append to our data array\n",
    "    entry = {\n",
    "        'response': response,\n",
    "        'score': match,\n",
    "        'temperature': temperature,\n",
    "        'repeat': repeat,\n",
    "    }\n",
    "\n",
    "    entry.update(inference_metadata)\n",
    "    data.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data, we can clean up the dataframe for data analysis. However, there is a small issue. When we use `DataFrame.dropna()`, we lose 4 rows, which means something happened during the data extraction process that resulted in the loss of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>score</th>\n",
       "      <th>temperature</th>\n",
       "      <th>repeat</th>\n",
       "      <th>numGpuLayers</th>\n",
       "      <th>predictedTokensCount</th>\n",
       "      <th>promptTokensCount</th>\n",
       "      <th>stopReason</th>\n",
       "      <th>timeToFirstTokenSec</th>\n",
       "      <th>tokensPerSecond</th>\n",
       "      <th>totalTokensCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>319</td>\n",
       "      <td>233</td>\n",
       "      <td>eosFound</td>\n",
       "      <td>0.039</td>\n",
       "      <td>25.702527</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>311</td>\n",
       "      <td>233</td>\n",
       "      <td>eosFound</td>\n",
       "      <td>0.039</td>\n",
       "      <td>25.724358</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>185</td>\n",
       "      <td>233</td>\n",
       "      <td>eosFound</td>\n",
       "      <td>0.040</td>\n",
       "      <td>26.844138</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>105</td>\n",
       "      <td>233</td>\n",
       "      <td>eosFound</td>\n",
       "      <td>0.040</td>\n",
       "      <td>25.531741</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>334</td>\n",
       "      <td>233</td>\n",
       "      <td>eosFound</td>\n",
       "      <td>0.039</td>\n",
       "      <td>25.821087</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     response  score  temperature  repeat  numGpuLayers  predictedTokensCount  \\\n",
       "705         9    NaN          0.6       8          -1.0                   319   \n",
       "71          2    NaN          0.6       7          -1.0                   311   \n",
       "651         4    NaN          0.8      11          -1.0                   185   \n",
       "559         1    NaN          0.0       3          -1.0                   105   \n",
       "26          9    NaN          0.6      10          -1.0                   334   \n",
       "\n",
       "     promptTokensCount stopReason  timeToFirstTokenSec  tokensPerSecond  \\\n",
       "705                233   eosFound                0.039        25.702527   \n",
       "71                 233   eosFound                0.039        25.724358   \n",
       "651                233   eosFound                0.040        26.844138   \n",
       "559                233   eosFound                0.040        25.531741   \n",
       "26                 233   eosFound                0.039        25.821087   \n",
       "\n",
       "     totalTokensCount  \n",
       "705               552  \n",
       "71                544  \n",
       "651               418  \n",
       "559               338  \n",
       "26                567  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# By creating a separate \"clean_df\", we can see which indices were removed when we dropna.\n",
    "clean_df = df.dropna()\n",
    "dropped_indices = set(df.index) - set(clean_df.index)\n",
    "dropped_df = df.loc[list(dropped_indices)]\n",
    "dropped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the regex pattern did not work because these expressed their scores as a fraction, as well as some that did not have it in a JSON format. Instead of ignoring these results, we will input them manually instead since it's just 4 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 11)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['temperature'] == 0.6) & (df['response'] == 2) & (df['repeat'] == 7), 'score'] = 4\n",
    "df.loc[(df['temperature'] == 0.6) & (df['response'] == 9) & (df['repeat'] == 10), 'score'] = 4\n",
    "df.loc[(df['temperature'] == 0.6) & (df['response'] == 9) & (df['repeat'] == 8), 'score'] = 5\n",
    "df.loc[(df['temperature'] == 0.0) & (df['response'] == 1) & (df['repeat'] == 3), 'score'] = 0\n",
    "df.loc[(df['temperature'] == 0.8) & (df['response'] == 4) & (df['repeat'] == 11), 'score'] = 3\n",
    "\n",
    "df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "The questions we want to answer are as follows:\n",
    "* How does temperature affect variance in solutions?\n",
    "* Is variance a predictor for potential inaccuracies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['response', 'score', 'temperature', 'repeat', 'numGpuLayers',\n",
       "       'predictedTokensCount', 'promptTokensCount', 'stopReason',\n",
       "       'timeToFirstTokenSec', 'tokensPerSecond', 'totalTokensCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature/Response combinations that have non-normally distributed results: 95.0%\n"
     ]
    }
   ],
   "source": [
    "# We generate descriptive statistics for every response/temperature combination\n",
    "stats_df = df.groupby(['response', 'temperature'])['score'].describe().reset_index()\n",
    "\n",
    "# To ensure that mean/std is appropriate, we perform the Shapiro-Wilk test to test for normality.\n",
    "normality_results = []\n",
    "\n",
    "for (resp, temp), group in df.groupby(['response', 'temperature']):\n",
    "    stat, p_value = stats.shapiro(group['score'])\n",
    "    normality_results.append({\n",
    "        'response': resp,\n",
    "        'temperature': temp,\n",
    "        'p_value': p_value,\n",
    "        'is_normal': p_value > 0.05\n",
    "    })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "stats_df = pd.merge(stats_df, normality_df, on=['response', 'temperature'])\n",
    "\n",
    "# Now we want to see how many of these data points are non-normal\n",
    "print(f\"Temperature/Response combinations that have non-normally distributed results: {((stats_df['is_normal'] == False).sum()/len(stats_df['is_normal'])) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 95% of our data is non-normal, we will instead use median and IQR to quantify the variance of our grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature  response  median  iqr\n",
       "0           0.0         1     4.0  1.0\n",
       "48          0.0         9     4.0  1.0\n",
       "42          0.0         8     4.0  1.0\n",
       "36          0.0         7     4.0  1.0\n",
       "6           0.0         2     4.0  0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create temporary dataframe with all the statistics we need\n",
    "stats_df = df.groupby(['response', 'temperature'])['score'].agg([\n",
    "    'median',\n",
    "    lambda x: x.quantile(0.25),\n",
    "    lambda x: x.quantile(0.75)\n",
    "]).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "stats_df.columns = ['response', 'temperature', 'median', 'q1', 'q3']\n",
    "\n",
    "# Calculate IQR\n",
    "stats_df['iqr'] = stats_df['q3'] - stats_df['q1']\n",
    "\n",
    "# Keep only the requested columns\n",
    "stats_df = stats_df[['temperature', 'response', 'median', 'iqr']].sort_values('temperature')\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see if temperature has an effect on the variance of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>p_value</th>\n",
       "      <th>is_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.394405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.190991</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.537484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.176996</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.459468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  count  mean       std  min    25%   50%    75%  max   p_value  \\\n",
       "0          0.0   10.0  0.90  0.394405  0.0  1.000  1.00  1.000  1.5  0.003622   \n",
       "1          0.2   10.0  0.60  0.516398  0.0  0.125  0.50  1.000  1.5  0.190991   \n",
       "2          0.4   10.0  0.75  0.353553  0.0  0.500  1.00  1.000  1.0  0.002088   \n",
       "3          0.6   10.0  1.00  0.408248  0.5  0.625  1.00  1.375  1.5  0.035215   \n",
       "4          0.8   10.0  0.80  0.537484  0.0  0.500  1.00  1.000  1.5  0.176996   \n",
       "5          1.0   10.0  0.60  0.459468  0.0  0.125  0.75  1.000  1.0  0.004219   \n",
       "\n",
       "   is_normal  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "3      False  \n",
       "4       True  \n",
       "5      False  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df2 = stats_df.groupby(['temperature'])['iqr'].describe().reset_index()\n",
    "\n",
    "normality_results = []\n",
    "\n",
    "for (temp), group in stats_df.groupby(['temperature']):\n",
    "    stat, p_value = stats.shapiro(group['iqr'])\n",
    "    normality_results.append({\n",
    "        'temperature': temp[0],\n",
    "        'p_value': p_value,\n",
    "        'is_normal': p_value > 0.05\n",
    "    })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "stats_df2 = pd.merge(stats_df2, normality_df, on=['temperature'])\n",
    "\n",
    "stats_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the non-normality of the data, median and IQR will be plotted instead.\n",
    "\n",
    "The rest of the analysis was done in Prism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
